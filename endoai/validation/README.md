# validation

This folder contains scripts and utilities for evaluating and validating trained models in ENDOAI.

## Purpose

- Evaluate model performance on validation datasets.
- Compute metrics such as Dice score, IoU, and others.
- Provide scripts for model selection and comparison.

## Structure

- `evaluate.py` — Main evaluation script for segmentation models.
- Add additional scripts for other metrics or validation workflows as needed.

## Usage

Import and use `evaluate_model` from `evaluate.py` to compute metrics on your validation dataset.

## Guidelines

- Extend with additional metrics as your project evolves.
- Document each script and its intended use.

## See Also

- [../README.md](../README.md) — Project-level documentation.
